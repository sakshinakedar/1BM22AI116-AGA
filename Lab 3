import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

dataset, info = tfds.load('cifar10', with_info=True, as_supervised=True)
train_data, test_data = dataset['train'], dataset['test']

def preprocess_image(image, label):
    image = tf.image.resize(image, (32, 32))  # Resize (if needed)
    image = tf.cast(image, tf.float32) / 255.0  # Normalize [0,1]
    return image, label

train_data = train_data.map(preprocess_image).batch(128).shuffle(10000)
test_data = test_data.map(preprocess_image).batch(128)

plt.imshow(next(iter(train_data))[0][0])
plt.axis('off')
plt.show()

original_dim = (32, 32, 3)  # CIFAR-10 image size
latent_dim = 10  # Latent space size

inputs = layers.Input(shape=original_dim)
x = layers.Conv2D(32, (3, 3), activation='relu', strides=2, padding='same')(inputs)
x = layers.Conv2D(64, (3, 3), activation='relu', strides=2, padding='same')(x)
x = layers.Conv2D(128, (3, 3), activation='relu', strides=2, padding='same')(x)
x = layers.Flatten()(x)
x = layers.Dense(128, activation='relu')(x)

z_mean = layers.Dense(latent_dim)(x)
z_log_var = layers.Dense(latent_dim)(x)

def sampling(args):
    z_mean, z_log_var = args
    epsilon = tf.keras.backend.random_normal(shape=(tf.shape(z_mean)[0], latent_dim))
    return z_mean + tf.exp(0.5 * z_log_var) * epsilon

z = layers.Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])

latent_inputs = layers.Input(shape=(latent_dim,))
x = layers.Dense(4 * 4 * 128, activation='relu')(latent_inputs)
x = layers.Reshape((4, 4, 128))(x)
x = layers.Conv2DTranspose(128, (3, 3), activation='relu', strides=2, padding='same')(x)
x = layers.Conv2DTranspose(64, (3, 3), activation='relu', strides=2, padding='same')(x)
x = layers.Conv2DTranspose(32, (3, 3), activation='relu', strides=2, padding='same')(x)
decoded = layers.Conv2DTranspose(3, (3, 3), activation='sigmoid', padding='same')(x)

vae = models.Model(inputs, decoded)

xent_loss = tf.reduce_mean(tf.reduce_sum(tf.keras.losses.binary_crossentropy(inputs, decoded), axis=(1, 2)))
kl_loss = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1))
vae_loss = xent_loss + kl_loss

vae.add_loss(vae_loss)
vae.compile(optimizer='adam')
vae.fit(train_data, epochs=10, validation_data=test_data)
decoder = models.Model(latent_inputs, decoded)
def generate_images(n=10):
    random_latent_vectors = np.random.normal(size=(n, latent_dim))
    generated_images = decoder.predict(random_latent_vectors)

    plt.figure(figsize=(15, 5))
    for i in range(n):
        ax = plt.subplot(2, 5, i + 1)
        plt.imshow(generated_images[i])
        plt.axis('off')
    plt.show()

generate_images(n=10)  # Generate 10 new images

encoder = models.Model(inputs, z_mean)
latent_representations = encoder.predict(test_data.map(lambda x, y: x))

plt.figure(figsize=(8, 6))
plt.scatter(latent_representations[:, 0], latent_representations[:, 1], c='blue', alpha=0.5)
plt.title('Latent Space Representation')
plt.xlabel('z[0]')
plt.ylabel('z[1]')
plt.show()
